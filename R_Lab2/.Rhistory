risk$Gender <- as.factor(risk$Gender)
risk$State <- as.factor(risk$State)
risk$Risk <- as.factor(risk$Risk)
# 5. Визуализация данных в виде цветной матрицы рассеивания
plot(
x = risk[1:8],  # Выбор первых 8 колонок для отображения
col = palette[as.numeric(risk$Risk)],  # Окраска точек по уровню риска
pch = 10  # Использование символа "плюс" для точек
)
# 1. Загрузка данных из файла "Risk.csv"
risk <- read.csv("Risk.csv")
# 2. Просмотр первых строк данных с помощью head() и открытие в отдельном окне с помощью View()
head(risk)
# View(risk) # Используйте для интерактивного просмотра
# 3. Загрузка библиотеки RColorBrewer и создание цветовой палитры
library(RColorBrewer)
# Создание палитры с 3 цветами из набора "Set2"
palette <- brewer.pal(3, "Set2")
# 4. Преобразование категориальных переменных в факторы
risk$Gender <- as.factor(risk$Gender)
risk$State <- as.factor(risk$State)
risk$Risk <- as.factor(risk$Risk)
# 5. Визуализация данных в виде цветной матрицы рассеивания
plot(
x = risk[1:8],  # Выбор первых 8 колонок для отображения
col = palette[as.numeric(risk$Risk)],  # Окраска точек по уровню риска
pch = 10  # Использование символа "плюс" для точек
)
# 6. Построение диаграммы рассеивания возраста и индекса массы тела (BMI)
plot(
x = risk$BMI,
y = risk$Age,
col = palette[as.numeric(risk$Risk)],  # Окраска по уровню риска
pch = 19  # Использование заполненного круга
)
legend(
x = "topright",
legend = levels(risk$Risk),  # Метки для уровней риска
col = palette,
pch = 16  # Символы в легенде
)
# 7. Установка начального значения для генератора случайных чисел
set.seed(42)
# Это обеспечивает воспроизводимость результатов при повторном запуске
# 8. Загрузка пакета caret и создание индексов для разделения данных
library(caret)
indexes <- createDataPartition(risk$Risk, p = 0.8, list = FALSE)
# 9. Создание обучающей и тестовой выборок
train <- risk[indexes, ]
test <- risk[-indexes, ]
# 10. Определение количества строк в каждой выборке
nrow(train)
nrow(test)
# 12. Обучение модели методом k-ближайших соседей
knnModel <- knn3(
formula = Risk ~ Age + BMI + Gender + State.Rate,
data = train,
k = 3  # Используется 3 ближайших соседа
)
# 13. Прогнозирование результатов на тестовой выборке
knnPredictions <- predict(
object = knnModel,
newdata = test,
type = "class"
)
# Создание таблицы сопряженности для оценки модели
table(
x = knnPredictions,
y = test$Risk
)
# 14. Создание матрицы ошибок и вывод результатов
knnMatrix <- confusionMatrix(
data = knnPredictions,
reference = test$Risk
)
print(knnMatrix)
# 15. Загрузка библиотеки для деревьев решений
library(tree)
# 16. Обучение модели дерева решений
treeModel <- tree(
formula = Risk ~ Age + BMI + Gender + State.Rate,
data = train,
method = "class"
)
# Отображение краткой информации о модели
summary(treeModel)
# 17. Визуализация дерева решений
plot(treeModel)
text(treeModel)
# 19. Прогнозирование результатов модели дерева решений
treePredictions <- predict(
object = treeModel,
newdata = test,
type = "class"
)
# 20. Создание матрицы ошибок для дерева решений
treeMatrix <- confusionMatrix(
data = treePredictions,
reference = test$Risk
)
# 21. Вывод результатов и точности модели дерева решений
print(treeMatrix)
# 22. Загрузка библиотеки для нейронных сетей
library(nnet)
# 23. Обучение модели нейронной сети
neuralModel <- nnet(
formula = Risk ~ Age + BMI + Gender + State.Rate,
data = train,
size = 10,  # Количество нейронов в скрытом слое
decay = 0.00001,  # Регуляризация
maxit = 500  # Максимальное количество итераций
)
# 25. Загрузка библиотеки для визуализации нейронной сети
library(NeuralNetTools)
# 26. Визуализация нейронной сети
plotnet(neuralModel, alpha = 0.5)
# 27. Прогнозирование результатов нейронной сети
neuralPredictions <- predict(
object = neuralModel,
newdata = test[, 1:8],
type = "class"
)
# 28. Создание матрицы ошибок для нейронной сети
neuralMatrix <- confusionMatrix(
data = as.factor(neuralPredictions),
reference = test$Risk
)
print(neuralMatrix)
# 29. Вывод точности каждой модели
print(knnMatrix$overall[1])  # Точность k-NN
print(treeMatrix$overall[1])  # Точность дерева решений
print(neuralMatrix$overall[1])  # Точность нейронной сети
# 30. Сравнение результатов классификаторов и выбор лучшего
# 1. Загрузка данных из файла "Risk.csv"
risk <- read.csv("Risk.csv")
# 2. Просмотр первых строк данных с помощью head() и открытие в отдельном окне с помощью View()
head(risk)
# View(risk) # Используйте для интерактивного просмотра
# 3. Загрузка библиотеки RColorBrewer и создание цветовой палитры
library(RColorBrewer)
# Создание палитры с 3 цветами из набора "Set2"
palette <- brewer.pal(3, "Set2")
# 4. Преобразование категориальных переменных в факторы
risk$Gender <- as.factor(risk$Gender)
risk$State <- as.factor(risk$State)
risk$Risk <- as.factor(risk$Risk)
# 5. Визуализация данных в виде цветной матрицы рассеивания
plot(
x = risk[1:8],  # Выбор первых 8 колонок для отображения
col = palette[as.numeric(risk$Risk)],  # Окраска точек по уровню риска
pch = 10  # Использование символа "плюс" для точек
)
# 6. Построение диаграммы рассеивания возраста и индекса массы тела (BMI)
plot(
x = risk$BMI,
y = risk$Age,
col = palette[as.numeric(risk$Risk)],  # Окраска по уровню риска
pch = 19  # Использование заполненного круга
)
legend(
x = "topright",
legend = levels(risk$Risk),  # Метки для уровней риска
col = palette,
pch = 16  # Символы в легенде
)
# 7. Установка начального значения для генератора случайных чисел
set.seed(42)
# Это обеспечивает воспроизводимость результатов при повторном запуске
# 8. Загрузка пакета caret и создание индексов для разделения данных
library(caret)
library(ggplot2)
library(lattice)
indexes <- createDataPartition(risk$Risk, p = 0.8, list = FALSE)
# 9. Создание обучающей и тестовой выборок
train <- risk[indexes, ]
test <- risk[-indexes, ]
# 10. Определение количества строк в каждой выборке
nrow(train)
nrow(test)
# 12. Обучение модели методом k-ближайших соседей
knnModel <- knn3(
formula = Risk ~ Age + BMI + Gender + State.Rate,
data = train,
k = 3  # Используется 3 ближайших соседа
)
# 13. Прогнозирование результатов на тестовой выборке
knnPredictions <- predict(
object = knnModel,
newdata = test,
type = "class"
)
# Создание таблицы сопряженности для оценки модели
table(
x = knnPredictions,
y = test$Risk
)
# 14. Создание матрицы ошибок и вывод результатов
knnMatrix <- confusionMatrix(
data = knnPredictions,
reference = test$Risk
)
print(knnMatrix)
# 15. Загрузка библиотеки для деревьев решений
library(tree)
# 16. Обучение модели дерева решений
treeModel <- tree(
formula = Risk ~ Age + BMI + Gender + State.Rate,
data = train,
method = "class"
)
# Отображение краткой информации о модели
summary(treeModel)
# 17. Визуализация дерева решений
plot(treeModel)
text(treeModel)
# 19. Прогнозирование результатов модели дерева решений
treePredictions <- predict(
object = treeModel,
newdata = test,
type = "class"
)
# 20. Создание матрицы ошибок для дерева решений
treeMatrix <- confusionMatrix(
data = treePredictions,
reference = test$Risk
)
# 21. Вывод результатов и точности модели дерева решений
print(treeMatrix)
# 22. Загрузка библиотеки для нейронных сетей
library(nnet)
# 23. Обучение модели нейронной сети
neuralModel <- nnet(
formula = Risk ~ Age + BMI + Gender + State.Rate,
data = train,
size = 10,  # Количество нейронов в скрытом слое
decay = 0.00001,  # Регуляризация
maxit = 500  # Максимальное количество итераций
)
# 25. Загрузка библиотеки для визуализации нейронной сети
library(NeuralNetTools)
# 26. Визуализация нейронной сети
plotnet(neuralModel, alpha = 0.5)
# 27. Прогнозирование результатов нейронной сети
neuralPredictions <- predict(
object = neuralModel,
newdata = test[, 1:8],
type = "class"
)
# 28. Создание матрицы ошибок для нейронной сети
neuralMatrix <- confusionMatrix(
data = as.factor(neuralPredictions),
reference = test$Risk
)
print(neuralMatrix)
# 29. Вывод точности каждой модели
print(knnMatrix$overall[1])  # Точность k-NN
print(treeMatrix$overall[1])  # Точность дерева решений
print(neuralMatrix$overall[1])  # Точность нейронной сети
# 30. Сравнение результатов классификаторов и выбор лучшего
# 1. Загрузка данных из файла "Risk.csv"
risk <- read.csv("Risk.csv")
# 2. Просмотр первых строк данных с помощью head() и открытие в отдельном окне с помощью View()
head(risk)
# View(risk) # - для интерактивного просмотра
# 3. Загрузка библиотеки RColorBrewer и создание цветовой палитры
library(RColorBrewer)
# Создание палитры с 3 цветами из набора "Set2"
palette <- brewer.pal(3, "Set2")
# 4. Преобразование категориальных переменных в факторы
risk$Gender <- as.factor(risk$Gender)
risk$State <- as.factor(risk$State)
risk$Risk <- as.factor(risk$Risk)
# 5. Визуализация данных в виде цветной матрицы рассеивания
plot(
x = risk[1:8],  # Выбор первых 8 колонок для отображения
col = palette[as.numeric(risk$Risk)],  # Окраска точек по уровню риска
pch = 10  # Использование символа "плюс" для точек
)
# 6. Построение диаграммы рассеивания возраста и индекса массы тела (BMI)
plot(
x = risk$BMI,
y = risk$Age,
col = palette[as.numeric(risk$Risk)],  # Окраска по уровню риска
pch = 19  # Использование заполненного круга
)
legend(
x = "topright",
legend = levels(risk$Risk),  # Метки для уровней риска
col = palette,
pch = 16  # Символы в легенде
)
# 7. Установка начального значения для генератора случайных чисел
set.seed(42)
# Это обеспечивает воспроизводимость результатов при повторном запуске
# 8. Загрузка пакета caret и создание индексов для разделения данных
library(caret)
library(ggplot2)
library(lattice)
indexes <- createDataPartition(risk$Risk, p = 0.8, list = FALSE)
# 9. Создание обучающей и тестовой выборок
train <- risk[indexes, ]
test <- risk[-indexes, ]
# 10. Определение количества строк в каждой выборке
nrow(train)
nrow(test)
# 12. Обучение модели методом k-ближайших соседей
knnModel <- knn3(
formula = Risk ~ Age + BMI + Gender + State.Rate,
data = train,
k = 3  # Используется 3 ближайших соседа
)
# 13. Прогнозирование результатов на тестовой выборке
knnPredictions <- predict(
object = knnModel,
newdata = test,
type = "class"
)
# Создание таблицы сопряженности для оценки модели
table(
x = knnPredictions,
y = test$Risk
)
# 14. Создание матрицы ошибок и вывод результатов
knnMatrix <- confusionMatrix(
data = knnPredictions,
reference = test$Risk
)
print(knnMatrix)
# 15. Загрузка библиотеки для деревьев решений
library(tree)
# 16. Обучение модели дерева решений
treeModel <- tree(
formula = Risk ~ Age + BMI + Gender + State.Rate,
data = train,
method = "class"
)
# Отображение краткой информации о модели
summary(treeModel)
# 17. Визуализация дерева решений
plot(treeModel)
text(treeModel)
# 19. Прогнозирование результатов модели дерева решений
treePredictions <- predict(
object = treeModel,
newdata = test,
type = "class"
)
# 20. Создание матрицы ошибок для дерева решений
treeMatrix <- confusionMatrix(
data = treePredictions,
reference = test$Risk
)
# 21. Вывод результатов и точности модели дерева решений
print(treeMatrix)
# 22. Загрузка библиотеки для нейронных сетей
library(nnet)
# 23. Обучение модели нейронной сети
neuralModel <- nnet(
formula = Risk ~ Age + BMI + Gender + State.Rate,
data = train,
size = 10,  # Количество нейронов в скрытом слое
decay = 0.00001,  # Регуляризация
maxit = 500  # Максимальное количество итераций
)
# 25. Загрузка библиотеки для визуализации нейронной сети
library(NeuralNetTools)
# 26. Визуализация нейронной сети
plotnet(neuralModel, alpha = 0.5)
# 27. Прогнозирование результатов нейронной сети
neuralPredictions <- predict(
object = neuralModel,
newdata = test[, 1:8],
type = "class"
)
# 28. Создание матрицы ошибок для нейронной сети
neuralMatrix <- confusionMatrix(
data = as.factor(neuralPredictions),
reference = test$Risk
)
print(neuralMatrix)
# 29. Вывод точности каждой модели
print(knnMatrix$overall[1])  # Точность k-NN
print(treeMatrix$overall[1])  # Точность дерева решений
print(neuralMatrix$overall[1])  # Точность нейронной сети
# 30. Сравнение результатов классификаторов и выбор лучшего
# 1. Загрузка данных из файла "Risk.csv"
risk <- read.csv("Risk.csv")
# 2. Просмотр первых строк данных с помощью head() и открытие в отдельном окне с помощью View()
head(risk)
# View(risk) # - для интерактивного просмотра
# 3. Загрузка библиотеки RColorBrewer и создание цветовой палитры
library(RColorBrewer)
# Создание палитры с 3 цветами из набора "Set2"
palette <- brewer.pal(3, "Set2")
# 4. Преобразование категориальных переменных в факторы
risk$Gender <- as.factor(risk$Gender)
risk$State <- as.factor(risk$State)
risk$Risk <- as.factor(risk$Risk)
# 5. Визуализация данных в виде цветной матрицы рассеивания
plot(
x = risk[1:8],  # Выбор первых 8 колонок для отображения
col = palette[as.numeric(risk$Risk)],  # Окраска точек по уровню риска
pch = 10  # Использование символа "плюс" для точек
)
# 6. Построение диаграммы рассеивания возраста и индекса массы тела (BMI)
plot(
x = risk$BMI, # BMI - Body Mass Index
y = risk$Age,
col = palette[as.numeric(risk$Risk)],  # Окраска по уровню риска
pch = 19  # Использование заполненного круга
)
legend(
x = "topright",
legend = levels(risk$Risk),  # Метки для уровней риска
col = palette,
pch = 16  # Символы в легенде
)
# 7. Установка начального значения для генератора случайных чисел
set.seed(42)
# Это обеспечивает воспроизводимость результатов при повторном запуске
# 8. Загрузка пакета caret и создание индексов для разделения данных
library(caret)
library(ggplot2)
library(lattice)
indexes <- createDataPartition(risk$Risk, p = 0.8, list = FALSE)
# 9. Создание обучающей и тестовой выборок
train <- risk[indexes, ]
test <- risk[-indexes, ]
# 10. Определение количества строк в каждой выборке
nrow(train)
nrow(test)
# 12. Обучение модели методом k-ближайших соседей
knnModel <- knn3(
formula = Risk ~ Age + BMI + Gender + State.Rate,
data = train,
k = 3  # Используется 3 ближайших соседа
)
# 13. Прогнозирование результатов на тестовой выборке
knnPredictions <- predict(
object = knnModel,
newdata = test,
type = "class"
)
# Создание таблицы сопряженности для оценки модели
table(
x = knnPredictions,
y = test$Risk
)
# 14. Создание матрицы ошибок и вывод результатов
knnMatrix <- confusionMatrix(
data = knnPredictions,
reference = test$Risk
)
print(knnMatrix)
# 15. Загрузка библиотеки для деревьев решений
library(tree)
# 16. Обучение модели дерева решений
treeModel <- tree(
formula = Risk ~ Age + BMI + Gender + State.Rate,
data = train,
method = "class"
)
# Отображение краткой информации о модели
summary(treeModel)
# 17. Визуализация дерева решений
plot(treeModel)
text(treeModel)
# 19. Прогнозирование результатов модели дерева решений
treePredictions <- predict(
object = treeModel,
newdata = test,
type = "class"
)
# 20. Создание матрицы ошибок для дерева решений
treeMatrix <- confusionMatrix(
data = treePredictions,
reference = test$Risk
)
# 21. Вывод результатов и точности модели дерева решений
print(treeMatrix)
# 22. Загрузка библиотеки для нейронных сетей
library(nnet)
# 23. Обучение модели нейронной сети
neuralModel <- nnet(
formula = Risk ~ Age + BMI + Gender + State.Rate,
data = train,
size = 10,  # Количество нейронов в скрытом слое
decay = 0.00001,  # Регуляризация
maxit = 500  # Максимальное количество итераций
)
# 25. Загрузка библиотеки для визуализации нейронной сети
library(NeuralNetTools)
# 26. Визуализация нейронной сети
plotnet(neuralModel, alpha = 0.5)
# 27. Прогнозирование результатов нейронной сети
neuralPredictions <- predict(
object = neuralModel,
newdata = test[, 1:8],
type = "class"
)
# 28. Создание матрицы ошибок для нейронной сети
neuralMatrix <- confusionMatrix(
data = as.factor(neuralPredictions),
reference = test$Risk
)
print(neuralMatrix)
# 29. Вывод точности каждой модели
print(knnMatrix$overall[1])  # Точность k-NN
print(treeMatrix$overall[1])  # Точность дерева решений
print(neuralMatrix$overall[1])  # Точность нейронной сети
# 30. Сравнение результатов классификаторов и выбор лучшего
View(risk) # - для интерактивного просмотра
